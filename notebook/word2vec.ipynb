{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-14T15:00:23.960615Z",
     "start_time": "2024-06-14T15:00:18.832970Z"
    }
   },
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tippy/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:08:20.048847Z",
     "start_time": "2024-06-14T15:08:20.042978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict"
   ],
   "id": "ad11728c9ff4f03f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:26:24.347646Z",
     "start_time": "2024-06-14T15:26:24.268681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TheLittlePrinceDataset:\n",
    "    def __init__(self, tokenizer=True):\n",
    "        with open('datas/TheLittlePrince.txt', 'r') as f:\n",
    "            text = f.read()\n",
    "            \n",
    "        if tokenizer:\n",
    "            self.sentences = sent_tokenize(text.lower())\n",
    "            self.tokens = [word_tokenize(sent) for sent in self.sentences]\n",
    "        else:\n",
    "            self.text = text\n",
    "            \n",
    "    def build_vocab(self, min_freq=1):\n",
    "        frequency = defaultdict(int)\n",
    "        for sent in self.tokens:\n",
    "            for word in sent:\n",
    "                frequency[word] += 1\n",
    "        self.frequency = frequency\n",
    "        \n",
    "        self.word2idx = {'<unk>': 1, '<pad>': 0}\n",
    "        self.idx2word = {1: '<unk>', 0: '<pad>'}\n",
    "        \n",
    "        for token, freq in sorted(frequency.items(), key=lambda x: -x[1]):\n",
    "            # 丢弃低频词\n",
    "            if freq > min_freq:\n",
    "                idx = len(self.word2idx)\n",
    "                self.word2idx[token] = idx\n",
    "                self.idx2word[idx] = token\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    def convert_tokens_to_ids(self, drop_single_word=True):\n",
    "        self.token_ids = []\n",
    "        for sent in self.tokens:\n",
    "            token_ids = [self.word2idx.get(word, 1) for word in sent]\n",
    "            \n",
    "            # 忽略只有一个词元的序列，无法计算损失\n",
    "            if drop_single_word and len(token_ids) == 1:\n",
    "                continue\n",
    "            self.token_ids.append(token_ids)\n",
    "            \n",
    "        return self.token_ids\n",
    "    \n",
    "dataset = TheLittlePrinceDataset()\n",
    "dataset.build_vocab()\n",
    "sentences = dataset.convert_tokens_to_ids()"
   ],
   "id": "8951862681e40959",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T15:26:25.349389Z",
     "start_time": "2024-06-14T15:26:25.266227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "window_size = 2\n",
    "data = []\n",
    "for sent in sentences:\n",
    "    for i in range(len(sent)):\n",
    "        for j in range(i-window_size,i+window_size+1):\n",
    "            if j < 0 or j >= len(sent) or i == j:\n",
    "                continue\n",
    "            center_word = sent[i]\n",
    "            context_word = sent[j]\n",
    "            data.append([center_word, context_word])\n",
    "\n",
    "import numpy as np\n",
    "data = np.array(data)\n",
    "data.shape, data"
   ],
   "id": "ede58707e1ac5753",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77380, 2),\n",
       " array([[  4,  17],\n",
       "        [  4,  20],\n",
       "        [ 17,   4],\n",
       "        ...,\n",
       "        [127,   3],\n",
       "        [  3,  84],\n",
       "        [  3, 127]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d56499bfbc7d948b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
